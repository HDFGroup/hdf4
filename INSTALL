***************************************************************************
  CONTENTS
  --------
  1. Obtaining the latest version

  2. Installing HDF/netCDF
  2.1 Supported Platforms
  2.2 Requirements
  2.3 General Configuration/Installation - Unix
  2.4 Platform-specific Notes
  2.5 Pablo Instrumentation
  2.6 File Cache(Beta release)
  2.7 Installation Location
  2.8 Specifying the System Type
  2.9 Configure Options 

  3. Man pages

  4. Release Notes

  5. 4.0 Documentation

  6. FAQ

  7. HELP

*****************************************************************************

1. Obtaining the latest version
============================

    The most recent version of the distribution can be obtained from
the NCSA ftp archive site at:

     ftp://ftp.ncsa.uiuc.edu/HDF/HDF4.0
or
     ftp://ftp.ncsa.uiuc.edu/HDF/HDF_Current

2. Installing HDF/netCDF	
=====================

    For compiling and installing HDF/netCDF libraries,tests and
    utilities on a system, please follow these instructions. 

2.1 Supported Platforms
    ===================

  For PLATFORM specific NOTES see the section below called
  'Platform-specific Notes'.


  Platform(OS)            C-Compiler  Fortran-Compiler   libdf.a   libmfhdf.a
  ------------            -----------  -----------------   -------   -----------
  Sun4(SunOS 4.1.4)           GCC 2.7.2      f77 SC1.0        X         X
  Sun4(Solaris 2.4)           CC SC3.0       f77 SC3.0        X         X
  Sun4(Solaris 2.5)           CC SC3.0       f77              X         X
  SGI-Indy(IRIX5.3)           CC             f77              X         X
  SGI-Indy(IRIX6.1_32)        CC 6.1         f77 6.1          X         X
  SGI-Indy(IRIX6.1_64)        CC 6.1         f77 6.1          X         X
  HP9000/735(HPUX 9.03)       CC             f77              X         X
  Exemplar(HPUX)              CC (for HPUX)  f77              X         X
  Cray C90 (UNICOS 803.2)     CC             cf77             X         X
  Cray YMP (UNICOS 803.2)     CC             cf77             X         X
  CM5 (Sun Frontend)          GCC 2.6.3      f77 SC1.0        X         X
  CM5 (Parallel I/O)          CSTAR 7.2      CMF 2.2.11       X         X
  IBM RS6000/AIX v3.2         xlc            f77              X         X
  IBM SP2 (single node)       xlc            f77              X         X
  DEC Alpha/Digital Unix v3.2 CC 3.11        f77              X         X
  DEC Alpha/OpenVMS AXP v6.2  DECC         DEC FORTRAN        X         X
  IBM PC - Intel Pentium
       Solarisx86             GCC 2.7.0       -               X         X
       Linux(a.out) v1.2.4    GCC         Fortran compiler    X         X
                                             2.6.2
                                 (Fortran to C converter)
       FreeBSD 2.0            GCC 2.6.2   Fortran compiler    X         X
                                             2.6.2
                                 (Fortran to C converter)

  PowerPC(Mac-OS-7.5)         Codewarrior 8    -              X         X
  68k-far/4i/8d(Mac-OS-7.5)   Codewarrior 8    -              X         X
  Windows NT/95               Visual C++ 4.0   -              X         X  
  VAX/VMS                        -             -              -         -  

2.2 Requirements
    ============

    To build both HDF and netCDF library from sources, you need:

      * ANSI C compiler. The native ANSI compilers on the above 
        platforms are supported. On platforms where no ANSI compiler
        was available the free GNU ANSI compiler GCC was used.

      * Fortran 77 compiler if you want Fortran support. See above
        table for platforms where Fortran is supported. You can
        compile both libraries without Fortran support by setting 
        the Fortran compiler variable 'FC = NONE' in the respective
        makefile fragment(mh-<os>) found in the top-level 'config'
        directory: 

                $(toplevel)/config/mh-<os>.

        See below for further details of configuration and installation.
        

2.3 General Configuration/Installation - Unix
    =========================================

    Overview
    --------        
    In this distribution there are two types of 'configure'
    scripts. One is the Cygnus 'configure' script and the other is the
    'configure' script created by the GNU autoconf package. The Cygnus
    'configure' script is used at the top level to configure the overall
    distribution and the HDF/MFHDF/IJPEG libraries. The GNU 'configure' script
    is used by the netCDF/IJPEG distributions to configure themselves. However, 
    these gnu configure scripts are not used in configuring this distribution.
 
    The Cygnus 'configure' script attempts to guess the correct
    platform you are configuring the distribution for by calling the shell
    script 'config.guess'. It outputs a unique string based on information
    obtained from the UNIX command 'uname' consisting of CPU-VENDOR-OS
    e.g. 'hppa1.1-hp-hpux9.03' for an  HP9000/735 running HPUX-9.03.

    Layout of configuration files
    -----------------------------
    The following shows the layout of the files used in the configuration
    of the HDF/MFHDF distribution..

    NOTE: The $(toplevel)/mfhdf/CUSTOMIZE and 
          $(toplevel)/mfhdf/configure(autoconf) files are no longer used 
          in the configuration of the distribution.
  
    $(toplevel)/Makefile.in
                config.guess
                config.sub
                configure (cygnus)
                configure.in (cygnus)
                config/mh-hpux, mh-sun,.....(host makefile fragments)

                man/Makefile.in

                mfhdf/CUSTOMIZE(not used)
                mfhdf/configure(autoconf - not used)
                mfhdf/libsrc/config/netcdf-aix.h,...  -> linked to netcdf.h
                mfhdf/fortran/config/ftest-aix.f,...  -> linked to ftest.f
                mfhdf/fortran/config/jackets-aix.c,.. -> linked to jackets.c
                mfhdf/fortran/config/netcdf-aix.inc,..-> linked to netcdf.inc

                hdf/Makefile.in
                hdf/src/Makefile.in
                hdf/test/Makefile.in
                hdf/util/Makefile.in
                hdf/zlib/Makefile.in
                hdf/pablo/Makefile.in

                hdf/jpeg/configure.in (cygnus)
                hdf/jpeg/Makefile.in
                hdf/jpeg/configure.gnu(autoconf - not used)
                hdf/jpeg/config/mh-hpux, mh-sun,... (host makefile fragments)
                hdf/jpeg/config/jhpux.h, jsun.h,...   -> linked to jconfig.h

                hdf/fmpool/configure, configure.in config.guess, config.sub,
                           Makefile.in (all cygnus)
                hdf/fmpool/config/mh-hpux, mh-sun,...(host makefile fragments)
                hdf/fmpool/config/fmpsolaris.h,...    -> linked to fmpconf.h

    Changing default values(CC,CFLAGS,..)
    -------------------------------------
    To change any of the default values for CC, FC, CFLAGS, FFLAGS,..etc
    edit the makefile fragment: 

             $(toplevel)/config/mh-<os>

    for your particular operating system. After changing the values you must 
    re-run the top-level 'configure' script. 

    It is also a good idea to look at the other variables to make sure 
    they are set correctly for your system.

    Running configure
    -----------------
    To build both of the libraries contained in this directory,
    run the ``configure'' script int $(toplevel), e.g.:

	./configure -v --prefix=/usr/local/hdf

    If you're using `csh' on an old version of System V, you might need 
    to type `sh ./configure -v --prefix=/usr/local/hdf' instead to prevent 
    `csh' from trying to execute `configure' itself.

    This will configure the distribution to install the libraries, utilities,
    include and man files in '/usr/local/hdf/lib','/usr/local/hdf/bin',
    '/usr/local/hdf/include' and '/usr/local/hdf/man' respectively. The
    default 'prefix' is '/usr/local'. It is advisable to use something
    like the above to avoid overwriting say another 'libjpeg.a' that might be
    installed in '/usr/local/lib'. The '-v' option is for verbose output.

    If the configure script can't determine your type of computer
    then it probably is a platfrom that is no longer supported.
    If you want to be adventurous see the section 'Dealing with
    Configure Problems' below. Otherwise send an email to 
    'hdfhelp@ncsa.uiuc.edu' for further help. 

    Dealing with Configure Problems
    *******************************
    If you want to be adventurous you can try the following.

    Configure basically calls either of the two shell scripts 'config.guess' 
    or 'config.sub' depending upon whether a target platfrom was supplied 
    on the command line to configure. If you don't provide a target on
    the command line configure calls 'config.guess' to guess what platfrom
    it is configuring for. The shell script 'config.guess' uses the unix
    command 'uname' to figure out the CPU, vendor, and OS of the
    platform. If you do provided a target on the command line, configure
    calls the shell script 'config.sub' to build the triplet specifying
    CPU, vendor, and OS from the full or partial target provided.

    If the configure script can't determine your type of computer, give it
    a general name that the computer is generally refered to as an argument, 
    for instance './configure sun4'.  You can use the script 'config.sub' 
    to test whether a general name is recognised; if it is, config.sub 
    translates it to a triplet specifying CPU, vendor, and OS.
    (e.g hppa1.1-hp-hpux9.03 for an HP900/735 running HPUX9.03).

    If this still fails all is not lost. All the configure script really
    needs is one of the supported targets mentioned above(except NT/Macintosh).
    If you think your platform is close to one of the above platforms
    mentioned in the 'Supported Platforms' sections you can pass configure
    this target and it will configure the distribution for that target..

    For possible mappings you will need to look inside the shell script
    'config.sub' and look at the partial to full mappings and pick one
    that satisfies the triplet mappings found in 'configure.in' below
    the section "# per-host:'. Note that if your try a mapping and it
    does not work this means that 'config.sub' needs to be edited to
    provide the proper mapping from your target to a full mapping that
    is supported. 

    There are currently NO instructions for Porting the distribution to a 
    new platform.

    Compiling, Testing and Installing
    ---------------------------------
    To compile the library and utilities type:

        make 

    To find out the available make targets type:

        make help

    To test the libraries and utilities type :

        make test 

    It is a good idea to save the output of the tests and view it later 
    for errors.
    e.g. 

        make test >& make.test.out

    To install the libraries, utilities, includes and man pages type: e.g.

        make install

2.4 Platform-specific Notes
    ========================

    HPUX(9.03) on PA-RISC
    ---------------------
    The distribution has been compiled/tested with both the native
    ANSI-C compiler and GCC 2.7.2. In both cases the native fortran
    compiler f77 was used. The binary distribution was compiled
    using the native compilers.

    IRIX(5.2) on MIPS
    -----------------
    The distribution has been compiled/tested with the native
    ANSI-C compiler and the fortran compiler. There is 
    a ansi prototype clash with the XDR header files on this version 
    of the OS that has been fixed in IRIX 5.3. It is recommended the 
    OS be upgraded to IRIX 5.3. Due to the ansi prototype clash, 
    the netCDF xdr tests will not compile with the -ansi option. To get 
    around this you can compile this test using the -cckr option and 
    then compile/run the remainder of the tests using the regular
    -ansi option. Note that the library compiles fine but that the 
    xdr netCDF test does not without the above fix. The binary 
    distribution was compiled using the native compilers.

    Solaris(2.5) on Sparc
    ---------------------
    The distribution has been compiled/tested with the native
    ANSI-C compiler and native fortran compiler. The binary 
    distribution was compiled using the native compilers.

    Solaris(2.4) on INTEL(x86)
    ---------------------------
    The distribution has been compiled/tested with GCC 2.7.0 with
    *NO* fortran support. The binary distribution was compiled
    using GCC 2.7.0.

    OpenVMS AXP on DEC Alpha
    ------------------------
    This is the first port of HDF4.0 to OpenVMS on DEC ALPHA. 
    Make.com files in each subdirectory are available to compile
    the libraries and utilites. The MAKENOF.COM and MAKEFS.COM
    in hdf/src are for compiling the C and Fortran programs
    respectively.  The package should be compiled in the following
    order: [.hdf.jpeg], [.hdf.zlib], [.hdf.src],[hdf.test], 
    [.hdf.util], [.mfhdf.xdr], [.mfhdf.libsrc],[.mfhdf.nctest],
    [.mfhdf.fortran.vms], [.mfhdf.ncdump],[.mfhdf.ncgen], and 
    [.mfhdf.dumper]. 

    Linking the example minigzip may fail due to an unresolved 
    symbol UNLINK. People from GZIP suggested to add the following at
    the beginning of minigzip.c and indicated the this fix will be
    included in zlib 1.0.

   #ifdef VMS
   #  define unlink delete
   #endif


    Windows '95 or Windows NT
    -------------------------
    To install on a Windows '95 or Windows NT machine, read the seperate
    installation instructions for Windows NT:
      
        $(toplevel)/release_notes/install_winNT.txt.
 
    CM5 Parallel I/O Extension
    --------------------------
    To install the parallel I/O extension for CM5, read the seperate 
    installation instructions in:

        $(toplevel)/release_notes/parallel_CM5.txt.

    PowerPC/68k(far/4i/8d)- Macintosh OS
    ------------------------------------
    The distribution was compilied/tested with MetroWerks Codewarrior(CW8).
    Only the base libraries{libdf.a,zlib.a,libjpeg.a,libmfhdf.a,libxdr.a}
    were compilied and tested on the PowerPC and 68k without Fortran support.

    The 68k version was compilied/tested using 4byte integers, 8byte doubles 
    and far option.

    *NO* Fortran support is included in this distribution.

    Codewarrior Projects can be found with this distrbution.
    They have been run through the Macintosh BinHex utility program. 
    You need to compile the libraries before you can compile the test 
    programs 'testhdf', 'xdrtest', 'cdftest', 'hdftest' and  'nctest'.

    Special Notes
    *************
    1. The test programs are SIOUX applications.
    
    2. When testing 'testhdf' in 'hdf/test' directory make sure
       that a directory called 'testdir' exists in the 'hdf/test'.
       This directory is used the the external element test.

    3. You need at least 8MB of memory to run most of the test programs.

    Configuring the Distribution
    ****************************
    A. If you have access to a unix box.

       1. Uncompress and untar the distribution.
       2. Type './configure mac'. This will build the distribution
          for the Macintosh. Specifically it will copy the correct
          files to the correct location. For the Macintosh release
          the two relevant files are the following: 

          mfhdf/libsrc/config/netcdf-mac.h  -> copied to mfhdf/libsrc/netcdf.h
          hdf/jpeg/config/jmac.h            -> copied to hdf/jpeg/jconfig.h

       3. Re-tar this newly configured distribution and download it
          the Macintosh where any utility that understands the tar format
          can be used to unpack it. If you dont' have acces to such a 
          utility then you need to copy the files one by one.

    B. Don't have access to a unix box and are using the 'tar.Z' version.
       1. After you have downloaded the distribution to your Macintosh
          you need to find a utility to uncompress and an untar the
          distribution.

       2. You will need to copy the following files to the correct locations
          with the new names(netcdf.h , jconfig.h).

          mfhdf/libsrc/config/netcdf-mac.h  -> copied to mfhdf/libsrc/netcdf.h
          hdf/jpeg/config/jmac.h            -> copied to hdf/jpeg/jconfig.h

    C. If you are using the 'sit.hqx' version everything should have
       been configured already.

    Building the Distribution
    *************************
    The distribution needs to be built in the order specifed below.
    Both PowerPC and 68k Codewarrior Projects can be found in the 
    following directories:
 
    $(toplevel)/
                hdf/zlib/zlib.68k-project.hqx
                         zlib.PPC-project.hqx

                hdf/jpeg/jpeglib.68k-project.hqx
                         jpeglib.PPC-project.hqx

                hdf/src/hdflib.68k-project.hqx
                        hdflib.PPC-project.hqx

                hdf/test/testhdf.68k-project.hqx
                         testhdf.68k-project.hqx

                hdf/test/testdir(need to create this if it does not exist)
    
                mfhdf/xdr/xdrlib.68k-project.hqx
                          xdrlib.PPC-project.hqx
                          xdrtest.68k-project.hqx
                          xdrtest.PPC-project.hqx

                mfhdf/libsrc/mfhdflib.68k-project.hqx
                             mfhdflib.PPC-project.hqx
                             cdftest.68k-project.hqx
                             cdftest.PPC-project.hqx
                             hdftest.68k-project.hqx
                             hdftest.PPC-project.hqx

                mfhdf/nctest/nctest.68k-project.hqx
                             nctest.PPC-project.hqx

    Testing the Distribution
    ************************
    Run the tests in the following order
      
       1. hdf/test/testhdf
          Note:
           When testing 'testhdf' in 'hdf/test' directory make sure
           that a directory called 'testdir' exists in the 'hdf/test'.
           This directory is used the the external element test.

       2. mfhdf/xdr/xdrtest
           After running this test compare the output to that shown in
           the file mfhdf/xdr/testout.sav

       3. mfhdf/libsrc/hdftest
           After running this test compare the ouput to that shown in
           the file mfhdf/libsrc/hdfout.sav

       4. mfhdf/libsrc/cdftest
           After running this test compare the ouput to that shown in
           the file mfhdf/libsrc/testout.sav

       5. mfhdf/nctest/nctest


2.5 Pablo Instrumentation
    ====================
    This version of the distribution has support to create an instrumented 
    version of the HDF library(libdf-inst.a). This library along
    the Pablo performance data capture libraries can be used to gather data
    about I/O behaviour and procedure execution times.  

    More detailed documentation on how to use the instrumented version of
    the HDF library with Pablo can be found in the Pablo directory: 

       $(toplevel)/hdf/pablo 

    See the provided '$(toplevel)/hdf/pablo/README.Pablo' and the PostScript 
    file '$(toplevel)/hdf/pablo/Pablo.ps'.

    At this time only an instrumented version of the core HDF library libdf.a 
    can be created. Future versions will have support for the SDxx interface
    found in libmfhdf.a. Current interfaces supported are ANxx, GRxx, DFSDxx,
    DFANxx, DFPxx, DFR8xx, DF24xx, Hxx, Vxx, and VSxx.

    To enable the creation of an instrumented library the following section
    in the makefile fragment($(toplevel)/config/mh-<os>) must be uncommented 
    and set.

    # ------------ Macros for Pablo Instrumentation  --------------------
    # Uncomment the following lines to create a Pablo Instrumentation
    # version of the HDF core library called 'libdf-inst.a'
    # See the documentation in the directory 'hdf/pablo' for further 
    # information about Pablo and what platforms it is supported on
    # before enabling. 
    # You need to set 'PABLO_INCLUDE' to the Pablo distribution 
    # include directory to get the files 'IOTrace.h' and 'IOTrace_SD.h'.
    #PABLO_FLAGS  = -DHAVE_PABLO
    #PABLO_INCLUDE = -I/hdf2/Pablo/Instrument.HP/include

    After setting these values you must re-run the toplevel 'configure' script.
    Make sure that your start from a clean re-build(i.e. 'make clean') after
    re-running the toplevel 'configure' script and then run 'make'.
    Details on running configure can be found above in the section
    'General Configuration/Installation - Unix'.

2.6 File Cache(Beta release)
    =================================
    This version of the distribution has preliminary support for file caching.

*NOTE*: This version is NOT officially supported on all platforms
        and has not been extensively tested. As such it is provided as is.
        It will be supported officially in a later release.

    The file cache allows the file to be mapped to user memory on 
    a per page basis i.e a memory pool of the file. With regards to the 
    file system, page sizes can be allocated based on the file system 
    page-size or if the user wants in some multiple of the file system 
    page-size. This allows for fewer pages to be managed along with 
    accommodating the users file usage pattern.

    The current version supports setting the page-size and number of pages
    in the memory pool through user C-routines(Fortran will be added in the
    next release). The default is 8192 bytes for page-size and 1 for number 
    of pages in the pool.

    More detailed documentation on how to use the file caching version 
    of the HDF library can be found in the directory'$(toplevel)/release_notes'.
    See the provided file '$(toplevel)/release_notes/page_buf.txt'

    To enable the creation of a library using page caching the following 
    section in the makefile fragment($(toplevel)/config/mh-<os>) must be 
    uncommented and set.

    # ------------ Macros for Shared Memory File Buffer Pool(fmpool) ------
    # Uncomment the following lines to enable shared memory file buffer pool
    # version of the HDF core library libdf.a. Please read the
    # documentation before enabling this feature.
    #FMPOOL_FLAGS  = -DHAVE_FMPOOL

    After setting these values you must re-run the toplevel 'configure' script.
    Make sure that your start from a clean re-build(i.e. 'make clean') after
    re-running the toplevel 'configure' script and then run 'make'.
    Details on running configure can be found above in the section
    'General Configuration/Installation - Unix'.


2.7 Installation Location
    =====================

    By default, `make install' will install the HDF/netCDF files in
    `/usr/local/bin', `/usr/local/man', etc.  You can specify an
    installation prefix other than `/usr/local' by giving `configure' the
    option `--prefix=PATH'. 

    eg.  ./configure -v --prefix=/usr/local/hdf

     This will configure the distribution to install the libraries, utilities,
     include and man files in '/usr/local/hdf/lib','/usr/local/hdf/bin',
     '/usr/local/hdf/include' and '/usr/local/hdf/man' respectively. The
     default 'prefix' is '/usr/local'. It is advisable to use something
     like the above to avoid overwriting say another 'libjpeg.a' that might be
     installed in '/usr/local/lib'.


2.8 Specifying the System Type
    ==========================

    There may be some features `configure' can not figure out
    automatically, but needs to determine by the type of host HDF/netCDF
    will run on.  Usually `configure' can figure that out, but if it prints
    a message saying it can not guess the host type, give it the
    `--host=TYPE' option.  TYPE can either be a short name for the system
    type, such as `sun4', or a canonical name with three fields:

         CPU-COMPANY-SYSTEM

    e.g. hppa1.1-hp-hpux9.03

    See the file `config.sub' for the possible values of each field.

    One system that requires this is the CM5. To configure properly
    for the parallel support on the CM5 you must type the following on the
    front end:

          ./configure -v CM5

2.9 Configure Options 
    ==================

    Usage: configure [OPTIONS] [HOST]

    Where HOST and TARGET are something like "sparc-sunos", "mips-sgi-irix5",etc.

    `configure' recognises the following options to control how it
    operates. 

    NOTE: not all options are currently supported by this
          distribution.The following are the only ones supported.

    `--help'
         Print a summary of the options to `configure', and exit.

     `--prefix=MYDIR`          install into MYDIR [/usr/local]


3. Man pages
   =============

    Manual pages for the library are not yet completed but some early
    drafts are available in:

         $(toplevel)/man.

4. Release notes
   =============
    The files in sub-directory $(toplevel)/release_notes are detailed 
    descriptions for the new features. They can be used as supplement 
    documentation for HDF4.0. Those files are also available on the NCSA 
    ftp server(ftp.ncsa.uiuc.edu) in:
 
         /HDF/Documentation/HDF4.0/4.0_release_notes/.

5. Documentation
   =============

   The HDF 4.0 documentation can be found on the NCSA ftp server
   in the directory /HDF/Documentation/HDF4.0/Users_Guide.  The
   HDF home page is at:

      http://hdf.ncsa.uiuc.edu/

6. FAQ
   ===
   An FAQ is available on our ftp server, as well as under
   "Information about HDF" in the home page.

7. HELP
   ====
   If you have any questions or comments, or would like to be
   added to or removed from our hdfnews email list, contact us
   at:

      hdfhelp@ncsa.uiuc.edu

