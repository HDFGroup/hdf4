All the input data files needed to test the utilities
are in the subdirectory testfiles/. To test the dump
function of hdfed, one may use the hdf file ntcheck.hdf
created by running tsdmms.c which is in the directory
../test/tsdmms.c.


Instructions on testing the HDF utility programs.


hdf24to8:

   Copy head.r24 in the testfiles directory.  

   Execute: 
        hdf24to8 head.r24 head8.hdf

   View head8.hdf.

   Not yet tested: error traps

ristosds:

   Copy the three HDF files storm110.hdf, storm120.hdf, and
   storm130.hdf from the testfiles/ directory.

   Execute:
        ristosds storm*.hdf -o storm.hdf
 
   Use hdfed to compare storm*.hdf with storm.hdf:
      In storm.hdf tag 702's element should be 38988 bytes.
      In storm110.hdf tag 302's element should be 12th of
         this, which is 3249.  (It is a 57x57 image.)
      Compare the first few numbers in storm110's image
      with the first few numbers in storm.hdf's SDS.  They
      should be the same.


hdfpack:

   Copy the file test.cdf from the testfiles/ directory.

   Execute:
        hdfpack test.cdf test.pck
        hdfpack -b test.cdf test.blk

   Use hdfls to get a listing of test.cdf and test.pck.  The only
       difference between the 2 listings should be that test.pck
       shouldn't have any special elements (they show up as "Unknown
       Tag") and it also shouldn't have any "Linked Block Indicators."
   Use the HDF browser to verify that the Vgroup named "Float" has a
       Vdata with ref no. 55 that contains the values:
       0.0, 1.0, 2.0,..., 359.0
   The file sizes should be as follows:
       test.cdf - 30272 
       test.pck - 22745 
       test.blk - 7245


hdftopal/paltohdf

   Copy the file palette.raw from the testfiles/ directory.

   Execute:
        paltohdf palette.raw palette.hdf
        hdftopal palette.hdf palette.raw.new

   Use hdfls with the '-l' option to examine the HDF palette file.
        It should have an 'Image Palette-8' and an 'Image Palette,'
        both with length 768 bytes.  They should also have the same
        reference number.
   Use the Unix utility 'cmp' or something similar to do a byte-for-byte
        comparison of palette.raw and palette.raw.new.  They should be
        identical.


r8tohdf/hdftor8

   Copy the files storm*.raw and palette.raw from the testfiles/ directory.

   Execute:
        r8tohdf 57 57 storm.hdf storm*.raw
        r8tohdf 57 57 storm.hdf -p palette.raw -i storm110.raw
        hdftor8 storm.hdf

   Use hdfls with the '-l' option to examine the HDF file.  It should
        contain five raster image sets, one of which will be compressed
        under IMCOMP compression.  (If you do not put the '-p' in the
        second r8tohdf command above, you should get an error message.)
        The non-compressed rasters images should be the same length as
        the raw raster files.  The compressed will be about 25% of that
        size.
   Use the Unix utility 'cmp' or something similar to do byte-for-byte
        comparisons on the produced raw raster files by hdftor8.  There
        should be one more than you had at the start.  One of them may
        not compare exactly with any one of the raw rasters, 
         and the rest will compare with one of
        the other raw rasters.  There is no guarantee about the order
        of the produced raw rasters, but it is likely they will be produced
        in the order in which they went into the file, which would be
        increasing numerical order, with the compressed image last.


hdfcomp

   Copy the files storm*.hdf from the testfiles/ directory.

   Execute:
        hdfcomp allstorms.hdf storm*.hdf
        hdfcomp allcomp.hdf -c storm*.hdf

   Use hdfls with the '-l' option to examine the two HDF files.  The first,
        allstorms.hdf, should simply hold the raster together in one file,
        with no compression.  You can use hdfls to check the original files.
        The second file, allcomp.hdf, should hold all the rasters in a
        compress format.  Run-Length Encoding (RLE) compression will result
        in modest savings - about 10% to 15% for these files.

hdfed

   Copy the file storm110.hdf from the testfiles/ directory.

   Execute:
        hdfed storm110.hdf

        Running interactively, type the following commands:

                info -all
                prev tag = 300
                info -long
                dump -short

        The latter two commands should result in the following responses:

         (6)    Image Dimensions              : (Tag 300)
                Ref: 110, Offset: 3459, Length: 20 (bytes)
       0:          0         57          0         57        106        110
      12:          1          0          0          0


        Type help and experiment.  Most of the information can be verified
        with hdfls.  Be sure to type 'close' then 'quit' when you are finished.

Caution: Hdfed has been revised so that it can dump data of various number
        types.  This function has been tested on SUN Station, CRAY2 and 
        CRAY-YMP. You are welcome to test on other platforms. If there is
        any problem or suggestio, please contact sxu@ncsa.uiuc.edu. 

        The program ../test/tsdmms.c tests DFSD* functions and creates an hdf
        file ntcheck.hdf whcih contains 8 SDS's. Their number types are:

	ref		number type

	2		DFNT_FLOAT64

	3		DFNT_FLOAT32

	4		DFNT_INT8

	5		DFNT_UINT8

	6		DFNT_INT16

	7		DFNT_UINT16

	8		DFNT_INT32

	9		DFNT_UINT32


        Ntcheck.hdf can be used as an input file to test the dump function. 

        The command:

	dump -help

        displays the list of formats supported by hdfed. 

        Commands:

        prev tag=<tag>  ref=<ref>

        and

        next tag=<rag> ref=<ref> 

        move you back and forth among the objects. 

        
        
